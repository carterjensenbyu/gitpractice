{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQltnZ0qxHf4B+BSEx9jjv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carterjensenbyu/gitpractice/blob/master/Take_Home_Assignment_7_7_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4OlH7n5ADP8",
        "outputId": "6047ccee-00fe-4005-b963-805d11903bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Take Home Assignment 7-7\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/My Drive/Take Home Assignment 7-7'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "idBIShpVAMzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iterate through folder and create dataframes for each csv\n",
        "\n",
        "for filename in os.listdir():\n",
        "  if filename.endswith('.csv'):\n",
        "    df_name = filename[:-4] # Remove the '.csv' extension to get the base name\n",
        "    globals()[df_name] = pd.read_csv(filename)\n",
        "    print(f'Created dataframe: {df_name}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEn5DzYnAO0Y",
        "outputId": "4e8513bd-0e2b-4dd9-fc67-c90916cc1ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataframe: site_5\n",
            "Created dataframe: site_6\n",
            "Created dataframe: site_3\n",
            "Created dataframe: site_1\n",
            "Created dataframe: site_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set firm service level baseline for each of the 5 sites\n",
        "\n",
        "site_1_fs = 10700\n",
        "site_2_fs = 5400\n",
        "site_3_fs = 850\n",
        "site_5_fs = 9000\n",
        "site_6_fs = 350"
      ],
      "metadata": {
        "id": "5ZLylbPJAR3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "\n",
        "cal = USFederalHolidayCalendar()\n",
        "\n",
        "# Get all defined dataframes that start with 'site_'\n",
        "site_dfs = {name: df for name, df in globals().items() if isinstance(df, pd.DataFrame) and name.startswith('site_')}\n",
        "\n",
        "# Find the overall min/max date across all site_dfs\n",
        "all_dates = pd.concat([df['Interval Beginning (EST)'] for df in site_dfs.values()])\n",
        "all_dates = pd.to_datetime(all_dates)\n",
        "holidays = cal.holidays(start=all_dates.min(), end=all_dates.max())\n",
        "holidays = set(holidays.date)  # Convert to set of date objects for fast lookup\n",
        "\n",
        "for name, df in site_dfs.items():\n",
        "    # Convert 'Interval Beginning (EST)' to datetime\n",
        "    df['Interval Beginning (EST)'] = pd.to_datetime(df['Interval Beginning (EST)'])\n",
        "\n",
        "    # Create a new column with just the date\n",
        "    df['Date'] = df['Interval Beginning (EST)'].dt.date\n",
        "\n",
        "    # Set 'Day Type' to 'Weekend' if holiday, else check for Saturday/Sunday\n",
        "    def get_day_type(date):\n",
        "        if date in holidays:\n",
        "            return 'Weekend'\n",
        "        elif pd.Timestamp(date).weekday() >= 5:\n",
        "            return 'Weekend'\n",
        "        else:\n",
        "            return 'Weekday'\n",
        "\n",
        "    df['Day Type'] = df['Date'].apply(get_day_type)\n",
        "\n",
        "    print(f\"Added 'Date' and 'Day Type' columns to {name}\")\n",
        "\n",
        "# checking modified dataframes\n",
        "print(site_1.head())\n",
        "print(site_2.head())\n",
        "print(site_3.head())\n",
        "print(site_5.head())\n",
        "print(site_6.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3Z6jqUaAYyQ",
        "outputId": "305dc54c-6798-498d-af13-86fcb1c5537d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'Date' and 'Day Type' columns to site_5\n",
            "Added 'Date' and 'Day Type' columns to site_6\n",
            "Added 'Date' and 'Day Type' columns to site_3\n",
            "Added 'Date' and 'Day Type' columns to site_1\n",
            "Added 'Date' and 'Day Type' columns to site_2\n",
            "  Interval Beginning (EST)     kWh        Date Day Type\n",
            "0      2022-05-02 00:00:00  1533.6  2022-05-02  Weekday\n",
            "1      2022-05-02 00:15:00  1490.4  2022-05-02  Weekday\n",
            "2      2022-05-02 00:30:00  1425.6  2022-05-02  Weekday\n",
            "3      2022-05-02 00:45:00  1414.8  2022-05-02  Weekday\n",
            "4      2022-05-02 01:00:00  1371.6  2022-05-02  Weekday\n",
            "  Interval Beginning (EST)   kWh        Date Day Type\n",
            "0      2022-05-02 00:00:00  72.0  2022-05-02  Weekday\n",
            "1      2022-05-02 00:15:00  72.0  2022-05-02  Weekday\n",
            "2      2022-05-02 00:30:00  72.0  2022-05-02  Weekday\n",
            "3      2022-05-02 00:45:00  75.6  2022-05-02  Weekday\n",
            "4      2022-05-02 01:00:00  72.0  2022-05-02  Weekday\n",
            "  Interval Beginning (EST)     kWh        Date Day Type\n",
            "0      2022-05-08 00:00:00  117.36  2022-05-08  Weekend\n",
            "1      2022-05-08 00:15:00  118.08  2022-05-08  Weekend\n",
            "2      2022-05-08 00:30:00  117.72  2022-05-08  Weekend\n",
            "3      2022-05-08 00:45:00  118.08  2022-05-08  Weekend\n",
            "4      2022-05-08 01:00:00  118.08  2022-05-08  Weekend\n",
            "  Interval Beginning (EST)      kWh        Date Day Type\n",
            "0      2022-05-11 00:00:00  2345.40  2022-05-11  Weekday\n",
            "1      2022-05-11 00:15:00  2341.32  2022-05-11  Weekday\n",
            "2      2022-05-11 00:30:00  2335.80  2022-05-11  Weekday\n",
            "3      2022-05-11 00:45:00  2321.40  2022-05-11  Weekday\n",
            "4      2022-05-11 01:00:00  2333.88  2022-05-11  Weekday\n",
            "  Interval Beginning (EST)    kWh        Date Day Type\n",
            "0      2022-05-02 00:00:00  38.34  2022-05-02  Weekday\n",
            "1      2022-05-02 00:15:00  38.52  2022-05-02  Weekday\n",
            "2      2022-05-02 00:30:00  38.16  2022-05-02  Weekday\n",
            "3      2022-05-02 00:45:00  38.16  2022-05-02  Weekday\n",
            "4      2022-05-02 01:00:00  37.80  2022-05-02  Weekday\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert kWh to kW and create new column\n",
        "for name, df in site_dfs.items():\n",
        "    df['kW'] = df['kWh'] / 0.25\n",
        "    print(f\"Added 'kW' column to {name}\")\n",
        "\n",
        "# checking modified dataframes\n",
        "print(site_1.head())\n",
        "print(site_2.head())\n",
        "print(site_3.head())\n",
        "print(site_5.head())\n",
        "print(site_6.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaAT4JxjAlZu",
        "outputId": "e25343ee-9921-4f6f-a260-a6ba6d1a87d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'kW' column to site_5\n",
            "Added 'kW' column to site_6\n",
            "Added 'kW' column to site_3\n",
            "Added 'kW' column to site_1\n",
            "Added 'kW' column to site_2\n",
            "  Interval Beginning (EST)     kWh        Date Day Type      kW\n",
            "0      2022-05-02 00:00:00  1533.6  2022-05-02  Weekday  6134.4\n",
            "1      2022-05-02 00:15:00  1490.4  2022-05-02  Weekday  5961.6\n",
            "2      2022-05-02 00:30:00  1425.6  2022-05-02  Weekday  5702.4\n",
            "3      2022-05-02 00:45:00  1414.8  2022-05-02  Weekday  5659.2\n",
            "4      2022-05-02 01:00:00  1371.6  2022-05-02  Weekday  5486.4\n",
            "  Interval Beginning (EST)   kWh        Date Day Type     kW\n",
            "0      2022-05-02 00:00:00  72.0  2022-05-02  Weekday  288.0\n",
            "1      2022-05-02 00:15:00  72.0  2022-05-02  Weekday  288.0\n",
            "2      2022-05-02 00:30:00  72.0  2022-05-02  Weekday  288.0\n",
            "3      2022-05-02 00:45:00  75.6  2022-05-02  Weekday  302.4\n",
            "4      2022-05-02 01:00:00  72.0  2022-05-02  Weekday  288.0\n",
            "  Interval Beginning (EST)     kWh        Date Day Type      kW\n",
            "0      2022-05-08 00:00:00  117.36  2022-05-08  Weekend  469.44\n",
            "1      2022-05-08 00:15:00  118.08  2022-05-08  Weekend  472.32\n",
            "2      2022-05-08 00:30:00  117.72  2022-05-08  Weekend  470.88\n",
            "3      2022-05-08 00:45:00  118.08  2022-05-08  Weekend  472.32\n",
            "4      2022-05-08 01:00:00  118.08  2022-05-08  Weekend  472.32\n",
            "  Interval Beginning (EST)      kWh        Date Day Type       kW\n",
            "0      2022-05-11 00:00:00  2345.40  2022-05-11  Weekday  9381.60\n",
            "1      2022-05-11 00:15:00  2341.32  2022-05-11  Weekday  9365.28\n",
            "2      2022-05-11 00:30:00  2335.80  2022-05-11  Weekday  9343.20\n",
            "3      2022-05-11 00:45:00  2321.40  2022-05-11  Weekday  9285.60\n",
            "4      2022-05-11 01:00:00  2333.88  2022-05-11  Weekday  9335.52\n",
            "  Interval Beginning (EST)    kWh        Date Day Type      kW\n",
            "0      2022-05-02 00:00:00  38.34  2022-05-02  Weekday  153.36\n",
            "1      2022-05-02 00:15:00  38.52  2022-05-02  Weekday  154.08\n",
            "2      2022-05-02 00:30:00  38.16  2022-05-02  Weekday  152.64\n",
            "3      2022-05-02 00:45:00  38.16  2022-05-02  Weekday  152.64\n",
            "4      2022-05-02 01:00:00  37.80  2022-05-02  Weekday  151.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adding hour column for interval beginning\n",
        "for name, df in site_dfs.items():\n",
        "    df['Hour'] = df['Interval Beginning (EST)'].dt.hour\n",
        "    print(f\"Added 'Hour' column to {name}\")\n",
        "\n",
        "# checking modified dataframes\n",
        "print(site_1)\n",
        "print(site_2.head())\n",
        "print(site_3.head())\n",
        "print(site_5.head())\n",
        "print(site_6.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZHimxjUAvxf",
        "outputId": "90765fb1-4ffe-4bf9-f66e-9a72b807f98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 'Hour' column to site_5\n",
            "Added 'Hour' column to site_6\n",
            "Added 'Hour' column to site_3\n",
            "Added 'Hour' column to site_1\n",
            "Added 'Hour' column to site_2\n",
            "     Interval Beginning (EST)     kWh        Date Day Type       kW  Hour\n",
            "0         2022-05-02 00:00:00  1533.6  2022-05-02  Weekday   6134.4     0\n",
            "1         2022-05-02 00:15:00  1490.4  2022-05-02  Weekday   5961.6     0\n",
            "2         2022-05-02 00:30:00  1425.6  2022-05-02  Weekday   5702.4     0\n",
            "3         2022-05-02 00:45:00  1414.8  2022-05-02  Weekday   5659.2     0\n",
            "4         2022-05-02 01:00:00  1371.6  2022-05-02  Weekday   5486.4     1\n",
            "...                       ...     ...         ...      ...      ...   ...\n",
            "4795      2022-06-20 22:45:00  3294.0  2022-06-20  Weekend  13176.0    22\n",
            "4796      2022-06-20 23:00:00  6091.2  2022-06-20  Weekend  24364.8    23\n",
            "4797      2022-06-20 23:15:00  4730.4  2022-06-20  Weekend  18921.6    23\n",
            "4798      2022-06-20 23:30:00  5821.2  2022-06-20  Weekend  23284.8    23\n",
            "4799      2022-06-20 23:45:00  4741.2  2022-06-20  Weekend  18964.8    23\n",
            "\n",
            "[4800 rows x 6 columns]\n",
            "  Interval Beginning (EST)   kWh        Date Day Type     kW  Hour\n",
            "0      2022-05-02 00:00:00  72.0  2022-05-02  Weekday  288.0     0\n",
            "1      2022-05-02 00:15:00  72.0  2022-05-02  Weekday  288.0     0\n",
            "2      2022-05-02 00:30:00  72.0  2022-05-02  Weekday  288.0     0\n",
            "3      2022-05-02 00:45:00  75.6  2022-05-02  Weekday  302.4     0\n",
            "4      2022-05-02 01:00:00  72.0  2022-05-02  Weekday  288.0     1\n",
            "  Interval Beginning (EST)     kWh        Date Day Type      kW  Hour\n",
            "0      2022-05-08 00:00:00  117.36  2022-05-08  Weekend  469.44     0\n",
            "1      2022-05-08 00:15:00  118.08  2022-05-08  Weekend  472.32     0\n",
            "2      2022-05-08 00:30:00  117.72  2022-05-08  Weekend  470.88     0\n",
            "3      2022-05-08 00:45:00  118.08  2022-05-08  Weekend  472.32     0\n",
            "4      2022-05-08 01:00:00  118.08  2022-05-08  Weekend  472.32     1\n",
            "  Interval Beginning (EST)      kWh        Date Day Type       kW  Hour\n",
            "0      2022-05-11 00:00:00  2345.40  2022-05-11  Weekday  9381.60     0\n",
            "1      2022-05-11 00:15:00  2341.32  2022-05-11  Weekday  9365.28     0\n",
            "2      2022-05-11 00:30:00  2335.80  2022-05-11  Weekday  9343.20     0\n",
            "3      2022-05-11 00:45:00  2321.40  2022-05-11  Weekday  9285.60     0\n",
            "4      2022-05-11 01:00:00  2333.88  2022-05-11  Weekday  9335.52     1\n",
            "  Interval Beginning (EST)    kWh        Date Day Type      kW  Hour\n",
            "0      2022-05-02 00:00:00  38.34  2022-05-02  Weekday  153.36     0\n",
            "1      2022-05-02 00:15:00  38.52  2022-05-02  Weekday  154.08     0\n",
            "2      2022-05-02 00:30:00  38.16  2022-05-02  Weekday  152.64     0\n",
            "3      2022-05-02 00:45:00  38.16  2022-05-02  Weekday  152.64     0\n",
            "4      2022-05-02 01:00:00  37.80  2022-05-02  Weekday  151.20     1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emergency_date = '2022-06-14'  # specific date of the emergency\n",
        "emergency_start_time = 13 # start time of the emergency (24-hour format)\n",
        "emergency_end_time = 17   # end time of the emergency (24-hour format)\n",
        "previous_days = 10 # number of previous days with which to calculate baseline"
      ],
      "metadata": {
        "id": "H4XkwuLKBBmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_average_baseline_kw(df, emergency_date_str, emergency_start_time_str, emergency_end_time_str, previous_days):\n",
        "    \"\"\"\n",
        "    Calculates the average baseline 'kW' for a given dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing energy data.\n",
        "        emergency_date_str (str): The date of the emergency in 'YYYY-MM-DD' format.\n",
        "        emergency_start_time_str (str): The start time of the emergency (24-hour format string).\n",
        "        emergency_end_time_str (str): The end time of the emergency (24-hour format string).\n",
        "        previous_days (int): The number of previous days to consider for the baseline.\n",
        "\n",
        "    Returns:\n",
        "        float: The average baseline 'kW' for the specified criteria.\n",
        "    \"\"\"\n",
        "    emergency_date = pd.to_datetime(emergency_date_str).date()\n",
        "    emergency_day_type = df[df['Date'] == emergency_date]['Day Type'].iloc[0]\n",
        "    emergency_start_hour = int(emergency_start_time_str)\n",
        "    emergency_end_hour = int(emergency_end_time_str)\n",
        "\n",
        "    # Filter for baseline days\n",
        "    baseline_df = df[\n",
        "        (df['Date'] < emergency_date) &\n",
        "        (df['Day Type'] == emergency_day_type)\n",
        "    ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "    # Get the unique dates in reverse order to easily select the last 'previous_days'\n",
        "    baseline_dates = sorted(baseline_df['Date'].unique(), reverse=True)\n",
        "\n",
        "    if len(baseline_dates) < previous_days:\n",
        "        print(f\"Warning: Not enough baseline days ({len(baseline_dates)}) found. Using all available days.\")\n",
        "        selected_baseline_dates = baseline_dates\n",
        "    else:\n",
        "        selected_baseline_dates = baseline_dates[:previous_days]\n",
        "\n",
        "    # Filter for the selected baseline dates and time window\n",
        "    filtered_baseline_df = baseline_df[\n",
        "        (baseline_df['Date'].isin(selected_baseline_dates)) &\n",
        "        (baseline_df['Hour'] >= emergency_start_hour) &\n",
        "        (baseline_df['Hour'] < emergency_end_hour)\n",
        "    ]\n",
        "\n",
        "    if filtered_baseline_df.empty:\n",
        "        print(\"Warning: No data found for the specified baseline period and time window.\")\n",
        "        return np.nan  # Return Not a Number if no data is found\n",
        "\n",
        "    average_baseline_kw = filtered_baseline_df['kW'].mean()\n",
        "\n",
        "    return average_baseline_kw\n",
        "\n",
        "# iterate and return baselines for each site\n",
        "baseline_results = {}\n",
        "for name, df in site_dfs.items():\n",
        "    average_kw = calculate_average_baseline_kw(df, emergency_date, emergency_start_time, emergency_end_time, previous_days)\n",
        "    baseline_results[name] = average_kw\n",
        "    print(f\"Average baseline kW for {name}: {average_kw}\")\n",
        "\n",
        "# show baseline kW results\n",
        "print(\"\\nBaseline results for all sites:\")\n",
        "print(baseline_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bszii9paBZlP",
        "outputId": "a5c722c3-bb11-4a70-ed3b-780ef8a8f25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average baseline kW for site_5: 9264.813\n",
            "Average baseline kW for site_6: 296.8965\n",
            "Average baseline kW for site_3: 649.3050000000001\n",
            "Average baseline kW for site_1: 11300.310000000001\n",
            "Average baseline kW for site_2: 4669.65\n",
            "\n",
            "Baseline results for all sites:\n",
            "{'site_5': np.float64(9264.813), 'site_6': np.float64(296.8965), 'site_3': np.float64(649.3050000000001), 'site_1': np.float64(11300.310000000001), 'site_2': np.float64(4669.65)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping site names (based on dataframe name) to their firm service levels\n",
        "firm_service_levels = {\n",
        "  'site_1': site_1_fs,\n",
        "  'site_2': site_2_fs,\n",
        "  'site_3': site_3_fs,\n",
        "  'site_5': site_5_fs,\n",
        "  'site_6': site_6_fs\n",
        "}\n",
        "\n",
        "def calculate_overall_performance(df, site_name, emergency_date_str, emergency_start_time_str, emergency_end_time_str, baseline_type):\n",
        "  \"\"\"\n",
        "  Calculates the performance for a given site on the emergency date within the specified time frame,\n",
        "  using either a calculated baseline or a firm service level baseline.\n",
        "\n",
        "  Args:\n",
        "  df (pd.DataFrame): The input DataFrame containing energy data for a specific site.\n",
        "  site_name (str): The name of the site (e.g., 'site_1'). Used to look up firm service level.\n",
        "  emergency_date_str (str): The date of the emergency in 'YYYY-MM-DD' format.\n",
        "  emergency_start_time_str (str): The start time of the emergency (24-hour format string).\n",
        "  emergency_end_time_str (str): The end time of the emergency (24-hour format string).\n",
        "  baseline_type (str): The type of baseline to use.\n",
        "  'calculate': Uses the calculated average baseline kW.\n",
        "  'fs': Uses the firm service level baseline.\n",
        "  Defaults to 'calculate'.\n",
        "\n",
        "  Returns:\n",
        "  float: The performance of the site during the emergency based on the chosen baseline type.\n",
        "  Returns np.nan if no data is found for the emergency period or if baseline is invalid.\n",
        "  \"\"\"\n",
        "  emergency_date = pd.to_datetime(emergency_date_str).date()\n",
        "  emergency_start_hour = int(emergency_start_time_str)\n",
        "  emergency_end_hour = int(emergency_end_time_str)\n",
        "\n",
        "  # Filter data for the emergency date and time window\n",
        "  emergency_df = df[\n",
        "      (df['Date'] == emergency_date) &\n",
        "      (df['Hour'] >= emergency_start_hour) &\n",
        "      (df['Hour'] < emergency_end_hour)\n",
        "  ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "  if emergency_df.empty:\n",
        "    print(f\"Warning: No data found for the emergency period on {emergency_date_str} between hour {emergency_start_hour} and {emergency_end_hour}.\")\n",
        "    return np.nan # Return Not a Number if no data is found\n",
        "\n",
        "  if baseline_type == '10of10':\n",
        "    # Use the pre-calculated 10of10 baseline kW\n",
        "    if site_name in baseline_results and not pd.isna(baseline_results[site_name]):\n",
        "      baseline_kw = baseline_results[site_name]\n",
        "      emergency_df['Performance'] = baseline_kw - emergency_df['kW']\n",
        "      average_performance = emergency_df['Performance'].mean()\n",
        "      return average_performance\n",
        "    else:\n",
        "      print(f\"Error: Calculated baseline not found or is invalid for {site_name}.\")\n",
        "      return np.nan\n",
        "\n",
        "  elif baseline_type == 'fs':\n",
        "    # Use the firm service level baseline\n",
        "    if site_name in firm_service_levels:\n",
        "      baseline_kw = firm_service_levels[site_name]\n",
        "      emergency_df['Performance'] = baseline_kw - emergency_df['kW']\n",
        "      average_performance = emergency_df['Performance'].mean()\n",
        "      return average_performance\n",
        "    else:\n",
        "      print(f\"Error: Firm service level not defined for {site_name}.\")\n",
        "      return np.nan\n",
        "\n",
        "  else:\n",
        "    print(f\"Error: Invalid baseline_type '{baseline_type}'. Choose 'calculate' or 'fs'.\")\n",
        "    return np.nan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxDTGRRGCCfX",
        "outputId": "cde88a74-db65-41fd-8538-9fc872695f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Performance (10of10 Baseline) for site_5 on 2022-06-14: 3499.893\n",
            "Overall Performance (10of10 Baseline) for site_6 on 2022-06-14: -11.623499999999995\n",
            "Overall Performance (10of10 Baseline) for site_3 on 2022-06-14: 649.3050000000001\n",
            "Overall Performance (10of10 Baseline) for site_1 on 2022-06-14: 3937.410000000001\n",
            "Overall Performance (10of10 Baseline) for site_2 on 2022-06-14: 4344.75\n",
            "\n",
            "Overall Performance results (Calculated Baseline) for all sites on the emergency date:\n",
            "{'site_5': np.float64(3499.893), 'site_6': np.float64(-11.623499999999995), 'site_3': np.float64(649.3050000000001), 'site_1': np.float64(3937.410000000001), 'site_2': np.float64(4344.75)}\n",
            "Overall Performance (FS Baseline) for site_5 on 2022-06-14: 3235.08\n",
            "Overall Performance (FS Baseline) for site_6 on 2022-06-14: 41.480000000000004\n",
            "Overall Performance (FS Baseline) for site_3 on 2022-06-14: 850.0\n",
            "Overall Performance (FS Baseline) for site_1 on 2022-06-14: 3337.1\n",
            "Overall Performance (FS Baseline) for site_2 on 2022-06-14: 5075.1\n",
            "\n",
            "Overall Performance results (Firm Service Level Baseline) for all sites on the emergency date:\n",
            "{'site_5': np.float64(3235.08), 'site_6': np.float64(41.480000000000004), 'site_3': np.float64(850.0), 'site_1': np.float64(3337.1), 'site_2': np.float64(5075.1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate performance using the calculated baseline for all sites\n",
        "overall_performance_10of10 = {}\n",
        "for name, df in site_dfs.items():\n",
        "  site_performance = calculate_overall_performance(df, name, emergency_date, emergency_start_time, emergency_end_time, baseline_type='10of10')\n",
        "  overall_performance_10of10[name] = site_performance\n",
        "  print(f\"Overall Performance (10of10 Baseline) for {name} on {emergency_date}: {site_performance}\")\n",
        "\n",
        "print(\"\\nOverall Performance results (10of10 Baseline) for all sites on the emergency date:\")\n",
        "print(overall_performance_10of10)\n",
        "\n",
        "# Calculate performance using the firm service level baseline for all sites\n",
        "overall_performance_fs = {}\n",
        "for name, df in site_dfs.items():\n",
        "  site_performance = calculate_overall_performance(df, name, emergency_date, emergency_start_time, emergency_end_time, baseline_type='fs')\n",
        "  overall_performance_fs[name] = site_performance\n",
        "  print(f\"Overall Performance (FS Baseline) for {name} on {emergency_date}: {site_performance}\")\n",
        "\n",
        "print(\"\\nOverall Performance results (Firm Service Level Baseline) for all sites on the emergency date:\")\n",
        "print(overall_performance_fs)"
      ],
      "metadata": {
        "id": "LxxqIvmZEs5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_hourly_performance(df, site_name, emergency_date_str, emergency_start_time_str, emergency_end_time_str, baseline_type):\n",
        "    \"\"\"\n",
        "    Calculates the hourly performance for a given site on the emergency date within the specified time frame,\n",
        "    using either a calculated baseline or a firm service level baseline.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame containing energy data for a specific site.\n",
        "        site_name (str): The name of the site (e.g., 'site_1'). Used to look up firm service level and baseline results.\n",
        "        emergency_date_str (str): The date of the emergency in 'YYYY-MM-DD' format.\n",
        "        emergency_start_time_str (str): The start time of the emergency (24-hour format string).\n",
        "        emergency_end_time_str (str): The end time of the emergency (24-hour format string).\n",
        "        baseline_type (str): The type of baseline to use.\n",
        "                             '10of10': Uses the pre-calculated 10of10 average baseline kW.\n",
        "                             'fs': Uses the firm service level baseline.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with hourly performance for the emergency period.\n",
        "                      Returns an empty DataFrame if no data is found for the emergency period or if baseline is invalid.\n",
        "    \"\"\"\n",
        "    emergency_date = pd.to_datetime(emergency_date_str).date()\n",
        "    emergency_start_hour = int(emergency_start_time_str)\n",
        "    emergency_end_hour = int(emergency_end_time_str)\n",
        "\n",
        "    # Filter data for the emergency date and time window\n",
        "    emergency_df = df[\n",
        "        (df['Date'] == emergency_date) &\n",
        "        (df['Hour'] >= emergency_start_hour) &\n",
        "        (df['Hour'] < emergency_end_hour)\n",
        "    ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "    if emergency_df.empty:\n",
        "        print(f\"Warning: No data found for the emergency period on {emergency_date_str} between hour {emergency_start_hour} and {emergency_end_hour} for {site_name}.\")\n",
        "        return pd.DataFrame() # Return an empty DataFrame\n",
        "\n",
        "    if baseline_type == '10of10':\n",
        "        # Use the pre-calculated 10of10 baseline kW\n",
        "        if site_name in baseline_results and not pd.isna(baseline_results[site_name]):\n",
        "            baseline_kw = baseline_results[site_name]\n",
        "            # Calculate performance for each interval based on the average baseline\n",
        "            emergency_df['Performance_kW'] = baseline_kw - emergency_df['kW']\n",
        "        else:\n",
        "            print(f\"Error: Calculated baseline not found or is invalid for {site_name}.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    elif baseline_type == 'fs':\n",
        "        # Use the firm service level baseline\n",
        "        if site_name in firm_service_levels:\n",
        "            baseline_kw = firm_service_levels[site_name]\n",
        "            # Calculate performance for each interval based on the firm service level\n",
        "            emergency_df['Performance_kW'] = baseline_kw - emergency_df['kW']\n",
        "        else:\n",
        "            print(f\"Error: Firm service level not defined for {site_name}.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: Invalid baseline_type '{baseline_type}'. Choose '10of10' or 'fs'.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Aggregate performance by hour (average performance for each hour)\n",
        "    hourly_performance_df = emergency_df.groupby('Hour')['Performance_kW'].mean().reset_index()\n",
        "    hourly_performance_df['Site'] = site_name\n",
        "    hourly_performance_df = hourly_performance_df[['Site', 'Hour', 'Performance_kW']] # Reorder columns\n",
        "\n",
        "    return hourly_performance_df"
      ],
      "metadata": {
        "id": "PXyZZBN_ExrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Calculate hourly performance using the 10of10 baseline for all sites\n",
        "hourly_performance_10of10_dfs = []\n",
        "for name, df in site_dfs.items():\n",
        "    hourly_perf_df = calculate_hourly_performance(df, name, emergency_date, emergency_start_time, emergency_end_time, baseline_type='10of10')\n",
        "    if not hourly_perf_df.empty:\n",
        "        hourly_performance_10of10_dfs.append(hourly_perf_df)\n",
        "\n",
        "# Concatenate all hourly performance dataframes\n",
        "if hourly_performance_10of10_dfs:\n",
        "    all_sites_hourly_performance_10of10 = pd.concat(hourly_performance_10of10_dfs, ignore_index=True)\n",
        "    print(\"\\nHourly Performance results (10of10 Baseline) for all sites on the emergency date:\")\n",
        "    print(all_sites_hourly_performance_10of10)\n",
        "else:\n",
        "    print(\"\\nNo hourly performance data generated for the 10of10 baseline.\")\n",
        "\n",
        "# Example usage: Calculate hourly performance using the FS baseline for all sites\n",
        "hourly_performance_fs_dfs = []\n",
        "for name, df in site_dfs.items():\n",
        "    hourly_perf_df = calculate_hourly_performance(df, name, emergency_date, emergency_start_time, emergency_end_time, baseline_type='fs')\n",
        "    if not hourly_perf_df.empty:\n",
        "        hourly_performance_fs_dfs.append(hourly_perf_df)\n",
        "\n",
        "# Concatenate all hourly performance dataframes\n",
        "if hourly_performance_fs_dfs:\n",
        "    all_sites_hourly_performance_fs = pd.concat(hourly_performance_fs_dfs, ignore_index=True)\n",
        "    print(\"\\nHourly Performance results (Firm Service Level Baseline) for all sites on the emergency date:\")\n",
        "    print(all_sites_hourly_performance_fs)\n",
        "else:\n",
        "    print(\"\\nNo hourly performance data generated for the FS baseline.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfhRZqJXFToX",
        "outputId": "92eb6938-c783-4a28-d95b-9c224117c0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hourly Performance results (10of10 Baseline) for all sites on the emergency date:\n",
            "      Site  Hour  Performance_kW\n",
            "0   site_5    13       4182.8130\n",
            "1   site_5    14       3195.0930\n",
            "2   site_5    15       3012.0930\n",
            "3   site_5    16       3609.5730\n",
            "4   site_6    13       -101.9835\n",
            "5   site_6    14         -0.8235\n",
            "6   site_6    15         16.4565\n",
            "7   site_6    16         39.8565\n",
            "8   site_3    13        649.3050\n",
            "9   site_3    14        649.3050\n",
            "10  site_3    15        649.3050\n",
            "11  site_3    16        649.3050\n",
            "12  site_1    13       4053.5100\n",
            "13  site_1    14       3859.1100\n",
            "14  site_1    15       3729.5100\n",
            "15  site_1    16       4107.5100\n",
            "16  site_2    13       4342.0500\n",
            "17  site_2    14       4349.2500\n",
            "18  site_2    15       4338.4500\n",
            "19  site_2    16       4349.2500\n",
            "\n",
            "Hourly Performance results (Firm Service Level Baseline) for all sites on the emergency date:\n",
            "      Site  Hour  Performance_kW\n",
            "0   site_5    13         3918.00\n",
            "1   site_5    14         2930.28\n",
            "2   site_5    15         2747.28\n",
            "3   site_5    16         3344.76\n",
            "4   site_6    13          -48.88\n",
            "5   site_6    14           52.28\n",
            "6   site_6    15           69.56\n",
            "7   site_6    16           92.96\n",
            "8   site_3    13          850.00\n",
            "9   site_3    14          850.00\n",
            "10  site_3    15          850.00\n",
            "11  site_3    16          850.00\n",
            "12  site_1    13         3453.20\n",
            "13  site_1    14         3258.80\n",
            "14  site_1    15         3129.20\n",
            "15  site_1    16         3507.20\n",
            "16  site_2    13         5072.40\n",
            "17  site_2    14         5079.60\n",
            "18  site_2    15         5068.80\n",
            "19  site_2    16         5079.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For the hourly performance using the 10of10 baseline\n",
        "if 'all_sites_hourly_performance_10of10' in locals() and not all_sites_hourly_performance_10of10.empty:\n",
        "  all_sites_hourly_performance_10of10['Performance_MW'] = all_sites_hourly_performance_10of10['Performance_kW'] / 1000\n",
        "  print(\"\\nHourly Performance results (10of10 Baseline) with Performance_MW:\")\n",
        "  print(all_sites_hourly_performance_10of10)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for 10of10 baseline is not available to calculate Performance_MW.\")\n",
        "\n",
        "# For the hourly performance using the FS baseline\n",
        "if 'all_sites_hourly_performance_fs' in locals() and not all_sites_hourly_performance_fs.empty:\n",
        "  all_sites_hourly_performance_fs['Performance_MW'] = all_sites_hourly_performance_fs['Performance_kW'] / 1000\n",
        "  print(\"\\nHourly Performance results (Firm Service Level Baseline) with Performance_MW:\")\n",
        "  print(all_sites_hourly_performance_fs)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for FS baseline is not available to calculate Performance_MW.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z56Wo6VGaJj",
        "outputId": "c1da3d66-a592-4e31-ad57-b4d6f971b8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hourly Performance results (10of10 Baseline) with Performance_MW:\n",
            "      Site  Hour  Performance_kW  Performance_MW\n",
            "0   site_5    13       4182.8130        4.182813\n",
            "1   site_5    14       3195.0930        3.195093\n",
            "2   site_5    15       3012.0930        3.012093\n",
            "3   site_5    16       3609.5730        3.609573\n",
            "4   site_6    13       -101.9835       -0.101983\n",
            "5   site_6    14         -0.8235       -0.000823\n",
            "6   site_6    15         16.4565        0.016457\n",
            "7   site_6    16         39.8565        0.039857\n",
            "8   site_3    13        649.3050        0.649305\n",
            "9   site_3    14        649.3050        0.649305\n",
            "10  site_3    15        649.3050        0.649305\n",
            "11  site_3    16        649.3050        0.649305\n",
            "12  site_1    13       4053.5100        4.053510\n",
            "13  site_1    14       3859.1100        3.859110\n",
            "14  site_1    15       3729.5100        3.729510\n",
            "15  site_1    16       4107.5100        4.107510\n",
            "16  site_2    13       4342.0500        4.342050\n",
            "17  site_2    14       4349.2500        4.349250\n",
            "18  site_2    15       4338.4500        4.338450\n",
            "19  site_2    16       4349.2500        4.349250\n",
            "\n",
            "Hourly Performance results (Firm Service Level Baseline) with Performance_MW:\n",
            "      Site  Hour  Performance_kW  Performance_MW\n",
            "0   site_5    13         3918.00         3.91800\n",
            "1   site_5    14         2930.28         2.93028\n",
            "2   site_5    15         2747.28         2.74728\n",
            "3   site_5    16         3344.76         3.34476\n",
            "4   site_6    13          -48.88        -0.04888\n",
            "5   site_6    14           52.28         0.05228\n",
            "6   site_6    15           69.56         0.06956\n",
            "7   site_6    16           92.96         0.09296\n",
            "8   site_3    13          850.00         0.85000\n",
            "9   site_3    14          850.00         0.85000\n",
            "10  site_3    15          850.00         0.85000\n",
            "11  site_3    16          850.00         0.85000\n",
            "12  site_1    13         3453.20         3.45320\n",
            "13  site_1    14         3258.80         3.25880\n",
            "14  site_1    15         3129.20         3.12920\n",
            "15  site_1    16         3507.20         3.50720\n",
            "16  site_2    13         5072.40         5.07240\n",
            "17  site_2    14         5079.60         5.07960\n",
            "18  site_2    15         5068.80         5.06880\n",
            "19  site_2    16         5079.60         5.07960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Emergency period prices\n",
        "price_per_mwh_13 = 1500 # Example price for hour 13\n",
        "price_per_mwh_14 = 1800 # Example price for hour 14\n",
        "price_per_mwh_15 = 3000 # Example price for hour 15\n",
        "price_per_mwh_16 = 780 # Example price for hour 16\n",
        "\n",
        "# Dictionary to map hours to prices\n",
        "hourly_prices = {\n",
        "  13: price_per_mwh_13,\n",
        "  14: price_per_mwh_14,\n",
        "  15: price_per_mwh_15,\n",
        "  16: price_per_mwh_16,\n",
        "}\n",
        "\n",
        "\n",
        "# Function to add the price column based on the Hour and calculate $/MWh\n",
        "def add_price_column(df, hourly_prices):\n",
        "  \"\"\"\n",
        "  Adds a '$/MWh' column to the dataframe based on the 'Hour' column and a dictionary of hourly prices.\n",
        "\n",
        "  Args:\n",
        "  df (pd.DataFrame): The input DataFrame containing energy data with an 'Hour' column.\n",
        "  hourly_prices (dict): A dictionary where keys are hours (int) and values are prices in $/MWh (float).\n",
        "\n",
        "  Returns:\n",
        "  pd.DataFrame: The DataFrame with the added '$/MWh' column.\n",
        "  \"\"\"\n",
        "  # Create the '$/MWh' column by mapping the 'Hour' to the hourly prices\n",
        "  # Use .copy() to avoid SettingWithCopyWarning\n",
        "  df_copy = df.copy()\n",
        "  df_copy['$/MWh'] = df_copy['Hour'].map(hourly_prices)\n",
        "\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "S0AJZLN0HYAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the hourly performance dataframes\n",
        "if 'all_sites_hourly_performance_10of10' in locals() and not all_sites_hourly_performance_10of10.empty:\n",
        "  all_sites_hourly_performance_10of10 = add_price_column(all_sites_hourly_performance_10of10, hourly_prices)\n",
        "  print(\"\\nHourly Performance results (10of10 Baseline) with $/MWh:\")\n",
        "  print(all_sites_hourly_performance_10of10)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for 10of10 baseline is not available to add $/MWh column.\")\n",
        "\n",
        "if 'all_sites_hourly_performance_fs' in locals() and not all_sites_hourly_performance_fs.empty:\n",
        "  all_sites_hourly_performance_fs = add_price_column(all_sites_hourly_performance_fs, hourly_prices)\n",
        "  print(\"\\nHourly Performance results (Firm Service Level Baseline) with $/MWh:\")\n",
        "  print(all_sites_hourly_performance_fs)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for FS baseline is not available to add $/MWh column.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amzE1DdgH0B0",
        "outputId": "4b5ac97b-e7b5-4af8-d8d7-b96b6277f635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hourly Performance results (10of10 Baseline) with $/MWh:\n",
            "      Site  Hour  Performance_kW  Performance_MW  $/MWh\n",
            "0   site_5    13       4182.8130        4.182813   1500\n",
            "1   site_5    14       3195.0930        3.195093   1800\n",
            "2   site_5    15       3012.0930        3.012093   3000\n",
            "3   site_5    16       3609.5730        3.609573    780\n",
            "4   site_6    13       -101.9835       -0.101983   1500\n",
            "5   site_6    14         -0.8235       -0.000823   1800\n",
            "6   site_6    15         16.4565        0.016457   3000\n",
            "7   site_6    16         39.8565        0.039857    780\n",
            "8   site_3    13        649.3050        0.649305   1500\n",
            "9   site_3    14        649.3050        0.649305   1800\n",
            "10  site_3    15        649.3050        0.649305   3000\n",
            "11  site_3    16        649.3050        0.649305    780\n",
            "12  site_1    13       4053.5100        4.053510   1500\n",
            "13  site_1    14       3859.1100        3.859110   1800\n",
            "14  site_1    15       3729.5100        3.729510   3000\n",
            "15  site_1    16       4107.5100        4.107510    780\n",
            "16  site_2    13       4342.0500        4.342050   1500\n",
            "17  site_2    14       4349.2500        4.349250   1800\n",
            "18  site_2    15       4338.4500        4.338450   3000\n",
            "19  site_2    16       4349.2500        4.349250    780\n",
            "\n",
            "Hourly Performance results (Firm Service Level Baseline) with $/MWh:\n",
            "      Site  Hour  Performance_kW  Performance_MW  $/MWh\n",
            "0   site_5    13         3918.00         3.91800   1500\n",
            "1   site_5    14         2930.28         2.93028   1800\n",
            "2   site_5    15         2747.28         2.74728   3000\n",
            "3   site_5    16         3344.76         3.34476    780\n",
            "4   site_6    13          -48.88        -0.04888   1500\n",
            "5   site_6    14           52.28         0.05228   1800\n",
            "6   site_6    15           69.56         0.06956   3000\n",
            "7   site_6    16           92.96         0.09296    780\n",
            "8   site_3    13          850.00         0.85000   1500\n",
            "9   site_3    14          850.00         0.85000   1800\n",
            "10  site_3    15          850.00         0.85000   3000\n",
            "11  site_3    16          850.00         0.85000    780\n",
            "12  site_1    13         3453.20         3.45320   1500\n",
            "13  site_1    14         3258.80         3.25880   1800\n",
            "14  site_1    15         3129.20         3.12920   3000\n",
            "15  site_1    16         3507.20         3.50720    780\n",
            "16  site_2    13         5072.40         5.07240   1500\n",
            "17  site_2    14         5079.60         5.07960   1800\n",
            "18  site_2    15         5068.80         5.06880   3000\n",
            "19  site_2    16         5079.60         5.07960    780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate Total Revenue\n",
        "def calculate_total_revenue(df):\n",
        "  \"\"\"\n",
        "  Calculates the 'Total Revenue' column as 'Performance_MW' * '$/MWh'.\n",
        "\n",
        "  Args:\n",
        "  df (pd.DataFrame): The input DataFrame with 'Performance_MW' and '$/MWh' columns.\n",
        "\n",
        "  Returns:\n",
        "  pd.DataFrame: The DataFrame with the added 'Total Revenue' column.\n",
        "  \"\"\"\n",
        "  # Ensure the necessary columns exist and are not null\n",
        "  if 'Performance_MW' in df.columns and '$/MWh' in df.columns:\n",
        "    # Calculate Total Revenue\n",
        "    # Use .copy() to avoid SettingWithCopyWarning\n",
        "    df_copy = df.copy()\n",
        "    df_copy['Total Revenue'] = df_copy['Performance_MW'] * df_copy['$/MWh']\n",
        "    return df_copy\n",
        "  else:\n",
        "    print(\"Error: 'Performance_MW' or '$/MWh' columns not found in the DataFrame.\")\n",
        "    return df # Return the original DataFrame if columns are missing"
      ],
      "metadata": {
        "id": "8ZxAwh7AIC71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the hourly performance dataframes\n",
        "if 'all_sites_hourly_performance_10of10' in locals() and not all_sites_hourly_performance_10of10.empty:\n",
        "  all_sites_hourly_performance_10of10 = calculate_total_revenue(all_sites_hourly_performance_10of10)\n",
        "  print(\"\\nHourly Performance results (10of10 Baseline) with Total Revenue:\")\n",
        "  print(all_sites_hourly_performance_10of10)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for 10of10 baseline is not available to calculate Total Revenue.\")\n",
        "\n",
        "if 'all_sites_hourly_performance_fs' in locals() and not all_sites_hourly_performance_fs.empty:\n",
        "  all_sites_hourly_performance_fs = calculate_total_revenue(all_sites_hourly_performance_fs)\n",
        "  print(\"\\nHourly Performance results (Firm Service Level Baseline) with Total Revenue:\")\n",
        "  print(all_sites_hourly_performance_fs)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for FS baseline is not available to calculate Total Revenue.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NebH1WAqJqMD",
        "outputId": "30fe2fd0-14c5-4a8f-eb0a-cd42e5c5613d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hourly Performance results (10of10 Baseline) with Total Revenue:\n",
            "      Site  Hour  Performance_kW  Performance_MW  $/MWh  Total Revenue\n",
            "0   site_5    13       4182.8130        4.182813   1500     6274.21950\n",
            "1   site_5    14       3195.0930        3.195093   1800     5751.16740\n",
            "2   site_5    15       3012.0930        3.012093   3000     9036.27900\n",
            "3   site_5    16       3609.5730        3.609573    780     2815.46694\n",
            "4   site_6    13       -101.9835       -0.101983   1500     -152.97525\n",
            "5   site_6    14         -0.8235       -0.000823   1800       -1.48230\n",
            "6   site_6    15         16.4565        0.016457   3000       49.36950\n",
            "7   site_6    16         39.8565        0.039857    780       31.08807\n",
            "8   site_3    13        649.3050        0.649305   1500      973.95750\n",
            "9   site_3    14        649.3050        0.649305   1800     1168.74900\n",
            "10  site_3    15        649.3050        0.649305   3000     1947.91500\n",
            "11  site_3    16        649.3050        0.649305    780      506.45790\n",
            "12  site_1    13       4053.5100        4.053510   1500     6080.26500\n",
            "13  site_1    14       3859.1100        3.859110   1800     6946.39800\n",
            "14  site_1    15       3729.5100        3.729510   3000    11188.53000\n",
            "15  site_1    16       4107.5100        4.107510    780     3203.85780\n",
            "16  site_2    13       4342.0500        4.342050   1500     6513.07500\n",
            "17  site_2    14       4349.2500        4.349250   1800     7828.65000\n",
            "18  site_2    15       4338.4500        4.338450   3000    13015.35000\n",
            "19  site_2    16       4349.2500        4.349250    780     3392.41500\n",
            "\n",
            "Hourly Performance results (Firm Service Level Baseline) with Total Revenue:\n",
            "      Site  Hour  Performance_kW  Performance_MW  $/MWh  Total Revenue\n",
            "0   site_5    13         3918.00         3.91800   1500      5877.0000\n",
            "1   site_5    14         2930.28         2.93028   1800      5274.5040\n",
            "2   site_5    15         2747.28         2.74728   3000      8241.8400\n",
            "3   site_5    16         3344.76         3.34476    780      2608.9128\n",
            "4   site_6    13          -48.88        -0.04888   1500       -73.3200\n",
            "5   site_6    14           52.28         0.05228   1800        94.1040\n",
            "6   site_6    15           69.56         0.06956   3000       208.6800\n",
            "7   site_6    16           92.96         0.09296    780        72.5088\n",
            "8   site_3    13          850.00         0.85000   1500      1275.0000\n",
            "9   site_3    14          850.00         0.85000   1800      1530.0000\n",
            "10  site_3    15          850.00         0.85000   3000      2550.0000\n",
            "11  site_3    16          850.00         0.85000    780       663.0000\n",
            "12  site_1    13         3453.20         3.45320   1500      5179.8000\n",
            "13  site_1    14         3258.80         3.25880   1800      5865.8400\n",
            "14  site_1    15         3129.20         3.12920   3000      9387.6000\n",
            "15  site_1    16         3507.20         3.50720    780      2735.6160\n",
            "16  site_2    13         5072.40         5.07240   1500      7608.6000\n",
            "17  site_2    14         5079.60         5.07960   1800      9143.2800\n",
            "18  site_2    15         5068.80         5.06880   3000     15206.4000\n",
            "19  site_2    16         5079.60         5.07960    780      3962.0880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Site' and 'Total Revenue' for both dataframes\n",
        "if 'all_sites_hourly_performance_10of10' in locals() and not all_sites_hourly_performance_10of10.empty:\n",
        "  grouped_10of10 = all_sites_hourly_performance_10of10.groupby('Site')['Total Revenue'].sum().reset_index()\n",
        "  print(\"\\nGrouped Total Revenue (10of10 Baseline) by Site:\")\n",
        "  print(grouped_10of10)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for 10of10 baseline is not available to group by Site.\")\n",
        "\n",
        "if 'all_sites_hourly_performance_fs' in locals() and not all_sites_hourly_performance_fs.empty:\n",
        "  grouped_fs = all_sites_hourly_performance_fs.groupby('Site')['Total Revenue'].sum().reset_index()\n",
        "  print(\"\\nGrouped Total Revenue (Firm Service Level Baseline) by Site:\")\n",
        "  print(grouped_fs)\n",
        "else:\n",
        "  print(\"\\nHourly performance data for FS baseline is not available to group by Site.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnJmtJFjLaNw",
        "outputId": "58d38c78-b50f-491f-e2b4-9fbc17bd02e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grouped Total Revenue (10of10 Baseline) by Site:\n",
            "     Site  Total Revenue\n",
            "0  site_1    27419.05080\n",
            "1  site_2    30749.49000\n",
            "2  site_3     4597.07940\n",
            "3  site_5    23877.13284\n",
            "4  site_6      -73.99998\n",
            "\n",
            "Grouped Total Revenue (Firm Service Level Baseline) by Site:\n",
            "     Site  Total Revenue\n",
            "0  site_1     23168.8560\n",
            "1  site_2     35920.3680\n",
            "2  site_3      6018.0000\n",
            "3  site_5     22002.2568\n",
            "4  site_6       301.9728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input the customer percentage share of revenue for each site\n",
        "customer_share_percentage = {\n",
        "  'site_1': 0.64, # Example share for site 1\n",
        "  'site_2': 0.62, # Example share for site 2\n",
        "  'site_3': 0.56, # Example share for site 3\n",
        "  'site_5': 0.65, # Example share for site 5\n",
        "  'site_6': 0.51 # Example share for site 6\n",
        "}\n",
        "\n",
        "# Add the customer share as a new column to both grouped dataframes\n",
        "if 'grouped_10of10' in locals() and not grouped_10of10.empty:\n",
        "  grouped_10of10['Customer Share Percentage'] = grouped_10of10['Site'].map(customer_share_percentage)\n",
        "  # Calculate the customer share of revenue\n",
        "  grouped_10of10['Customer Revenue Share'] = grouped_10of10['Total Revenue'] * grouped_10of10['Customer Share Percentage']\n",
        "  # Ensure the value is not less than 0\n",
        "  grouped_10of10['Customer Revenue Share'] = grouped_10of10['Customer Revenue Share'].apply(lambda x: max(0, x))\n",
        "  print(\"\\nGrouped Total Revenue (10of10 Baseline) with Customer Revenue Share:\")\n",
        "  print(grouped_10of10)\n",
        "else:\n",
        "  print(\"\\nGrouped data for 10of10 baseline is not available to add customer revenue share.\")\n",
        "\n",
        "if 'grouped_fs' in locals() and not grouped_fs.empty:\n",
        "  grouped_fs['Customer Share Percentage'] = grouped_fs['Site'].map(customer_share_percentage)\n",
        "  # Calculate the customer share of revenue\n",
        "  grouped_fs['Customer Revenue Share'] = grouped_fs['Total Revenue'] * grouped_fs['Customer Share Percentage']\n",
        "  # Ensure the value is not less than 0\n",
        "  grouped_fs['Customer Revenue Share'] = grouped_fs['Customer Revenue Share'].apply(lambda x: max(0, x))\n",
        "  print(\"\\nGrouped Total Revenue (Firm Service Level Baseline) with Customer Revenue Share:\")\n",
        "  print(grouped_fs)\n",
        "else:\n",
        "  print(\"\\nGrouped data for FS baseline is not available to add customer revenue share.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W72MkjmTLsn5",
        "outputId": "307b981f-b1f6-4c8b-c0ee-4e42bcb6c7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grouped Total Revenue (10of10 Baseline) with Customer Revenue Share:\n",
            "     Site  Total Revenue  Customer Share Percentage  Customer Revenue Share\n",
            "0  site_1    27419.05080                       0.64            17548.192512\n",
            "1  site_2    30749.49000                       0.62            19064.683800\n",
            "2  site_3     4597.07940                       0.56             2574.364464\n",
            "3  site_5    23877.13284                       0.65            15520.136346\n",
            "4  site_6      -73.99998                       0.51                0.000000\n",
            "\n",
            "Grouped Total Revenue (Firm Service Level Baseline) with Customer Revenue Share:\n",
            "     Site  Total Revenue  Customer Share Percentage  Customer Revenue Share\n",
            "0  site_1     23168.8560                       0.64            14828.067840\n",
            "1  site_2     35920.3680                       0.62            22270.628160\n",
            "2  site_3      6018.0000                       0.56             3370.080000\n",
            "3  site_5     22002.2568                       0.65            14301.466920\n",
            "4  site_6       301.9728                       0.51              154.006128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Profit for 10of10 baseline\n",
        "if 'grouped_10of10' in locals() and not grouped_10of10.empty:\n",
        "  grouped_10of10['Profit'] = grouped_10of10['Total Revenue'] - grouped_10of10['Customer Revenue Share']\n",
        "  print(\"\\nGrouped Results (10of10 Baseline) with Profit:\")\n",
        "  print(grouped_10of10)\n",
        "else:\n",
        "  print(\"\\nGrouped data for 10of10 baseline is not available to calculate Profit.\")\n",
        "\n",
        "# Calculate Profit for FS baseline\n",
        "if 'grouped_fs' in locals() and not grouped_fs.empty:\n",
        "  grouped_fs['Profit'] = grouped_fs['Total Revenue'] - grouped_fs['Customer Revenue Share']\n",
        "  print(\"\\nGrouped Results (Firm Service Level Baseline) with Profit:\")\n",
        "  print(grouped_fs)\n",
        "else:\n",
        "  print(\"\\nGrouped data for FS baseline is not available to calculate Profit.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSEOFNiINDoB",
        "outputId": "5d6d9e68-5bcf-48ad-e7c0-2244257a2fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grouped Results (10of10 Baseline) with Profit:\n",
            "     Site  Total Revenue  Customer Share Percentage  Customer Revenue Share  \\\n",
            "0  site_1    27419.05080                       0.64            17548.192512   \n",
            "1  site_2    30749.49000                       0.62            19064.683800   \n",
            "2  site_3     4597.07940                       0.56             2574.364464   \n",
            "3  site_5    23877.13284                       0.65            15520.136346   \n",
            "4  site_6      -73.99998                       0.51                0.000000   \n",
            "\n",
            "         Profit  \n",
            "0   9870.858288  \n",
            "1  11684.806200  \n",
            "2   2022.714936  \n",
            "3   8356.996494  \n",
            "4    -73.999980  \n",
            "\n",
            "Grouped Results (Firm Service Level Baseline) with Profit:\n",
            "     Site  Total Revenue  Customer Share Percentage  Customer Revenue Share  \\\n",
            "0  site_1     23168.8560                       0.64            14828.067840   \n",
            "1  site_2     35920.3680                       0.62            22270.628160   \n",
            "2  site_3      6018.0000                       0.56             3370.080000   \n",
            "3  site_5     22002.2568                       0.65            14301.466920   \n",
            "4  site_6       301.9728                       0.51              154.006128   \n",
            "\n",
            "         Profit  \n",
            "0   8340.788160  \n",
            "1  13649.739840  \n",
            "2   2647.920000  \n",
            "3   7700.789880  \n",
            "4    147.966672  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format 'Total Revenue', 'Customer Revenue Share', and 'Profit' as dollars\n",
        "if 'grouped_10of10' in locals() and not grouped_10of10.empty:\n",
        "  grouped_10of10['Total Revenue'] = grouped_10of10['Total Revenue'].apply(lambda x: f'${x:,.2f}')\n",
        "  grouped_10of10['Customer Revenue Share'] = grouped_10of10['Customer Revenue Share'].apply(lambda x: f'${x:,.2f}')\n",
        "  grouped_10of10['Profit'] = grouped_10of10['Profit'].apply(lambda x: f'${x:,.2f}')\n",
        "  print(\"\\nGrouped Results (10of10 Baseline) with Dollar Formatting:\")\n",
        "  print(grouped_10of10)\n",
        "else:\n",
        "  print(\"\\nGrouped data for 10of10 baseline is not available to format as dollars.\")\n",
        "\n",
        "if 'grouped_fs' in locals() and not grouped_fs.empty:\n",
        "  grouped_fs['Total Revenue'] = grouped_fs['Total Revenue'].apply(lambda x: f'${x:,.2f}')\n",
        "  grouped_fs['Customer Revenue Share'] = grouped_fs['Customer Revenue Share'].apply(lambda x: f'${x:,.2f}')\n",
        "  grouped_fs['Profit'] = grouped_fs['Profit'].apply(lambda x: f'${x:,.2f}')\n",
        "  print(\"\\nGrouped Results (Firm Service Level Baseline) with Dollar Formatting:\")\n",
        "  print(grouped_fs)\n",
        "else:\n",
        "  print(\"\\nGrouped data for FS baseline is not available to format as dollars.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P8nHixWO2wW",
        "outputId": "c62ff5c7-292c-46be-dff1-8743a66d2ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Grouped Results (10of10 Baseline) with Dollar Formatting:\n",
            "     Site Total Revenue  Customer Share Percentage Customer Revenue Share  \\\n",
            "0  site_1    $27,419.05                       0.64             $17,548.19   \n",
            "1  site_2    $30,749.49                       0.62             $19,064.68   \n",
            "2  site_3     $4,597.08                       0.56              $2,574.36   \n",
            "3  site_5    $23,877.13                       0.65             $15,520.14   \n",
            "4  site_6       $-74.00                       0.51                  $0.00   \n",
            "\n",
            "       Profit  \n",
            "0   $9,870.86  \n",
            "1  $11,684.81  \n",
            "2   $2,022.71  \n",
            "3   $8,357.00  \n",
            "4     $-74.00  \n",
            "\n",
            "Grouped Results (Firm Service Level Baseline) with Dollar Formatting:\n",
            "     Site Total Revenue  Customer Share Percentage Customer Revenue Share  \\\n",
            "0  site_1    $23,168.86                       0.64             $14,828.07   \n",
            "1  site_2    $35,920.37                       0.62             $22,270.63   \n",
            "2  site_3     $6,018.00                       0.56              $3,370.08   \n",
            "3  site_5    $22,002.26                       0.65             $14,301.47   \n",
            "4  site_6       $301.97                       0.51                $154.01   \n",
            "\n",
            "       Profit  \n",
            "0   $8,340.79  \n",
            "1  $13,649.74  \n",
            "2   $2,647.92  \n",
            "3   $7,700.79  \n",
            "4     $147.97  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the dataframes to a single Excel file on different sheets\n",
        "output_folder = '/content/gdrive/My Drive/Take Home Results'\n",
        "output_filename = 'Revenue_Performance_Results.xlsx'\n",
        "output_filepath = os.path.join(output_folder, output_filename)\n",
        "\n",
        "# Ensure the output directory exists\n",
        "if not os.path.exists(output_folder):\n",
        "  os.makedirs(output_folder)\n",
        "  print(f\"Created output directory: {output_folder}\")\n",
        "\n",
        "# Use ExcelWriter to write to different sheets\n",
        "try:\n",
        "  with pd.ExcelWriter(output_filepath) as writer:\n",
        "    if 'grouped_10of10' in locals() and not grouped_10of10.empty:\n",
        "      grouped_10of10.to_excel(writer, sheet_name='10of10 Baseline Results', index=False)\n",
        "      print(f\"Wrote 'grouped_10of10' to sheet '10of10 Baseline Results'\")\n",
        "    else:\n",
        "      print(\"Skipping writing 'grouped_10of10' as it is not available or empty.\")\n",
        "\n",
        "    if 'grouped_fs' in locals() and not grouped_fs.empty:\n",
        "      grouped_fs.to_excel(writer, sheet_name='FS Baseline Results', index=False)\n",
        "      print(f\"Wrote 'grouped_fs' to sheet 'FS Baseline Results'\")\n",
        "    else:\n",
        "      print(\"Skipping writing 'grouped_fs' as it is not available or empty.\")\n",
        "\n",
        "  print(f\"\\nSuccessfully wrote results to {output_filepath}\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred while writing to Excel: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkLfFPANOUnM",
        "outputId": "f7c980fa-9c2e-42c0-c164-8845e8b70390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 'grouped_10of10' to sheet '10of10 Baseline Results'\n",
            "Wrote 'grouped_fs' to sheet 'FS Baseline Results'\n",
            "\n",
            "Successfully wrote results to /content/gdrive/My Drive/Take Home Results/Revenue_Performance_Results.xlsx\n"
          ]
        }
      ]
    }
  ]
}